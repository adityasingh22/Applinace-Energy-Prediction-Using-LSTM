{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing, model_selection, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the dataset in dataframe\n",
    "data = pd.read_csv(\"/home/adityasingh/Downloads/energydata_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Appliances</th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>...</th>\n",
       "      <th>T9</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-11 17:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>47.596667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.033333</td>\n",
       "      <td>45.53</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>733.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>5.3</td>\n",
       "      <td>13.275433</td>\n",
       "      <td>13.275433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-11 17:10:00</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.693333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.722500</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.066667</td>\n",
       "      <td>45.56</td>\n",
       "      <td>6.483333</td>\n",
       "      <td>733.6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>59.166667</td>\n",
       "      <td>5.2</td>\n",
       "      <td>18.606195</td>\n",
       "      <td>18.606195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-11 17:20:00</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.626667</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.933333</td>\n",
       "      <td>18.926667</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.50</td>\n",
       "      <td>6.366667</td>\n",
       "      <td>733.7</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>5.1</td>\n",
       "      <td>28.642668</td>\n",
       "      <td>28.642668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-11 17:30:00</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.590000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>733.8</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.410389</td>\n",
       "      <td>45.410389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-11 17:40:00</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.530000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>45.40</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>733.9</td>\n",
       "      <td>92.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.084097</td>\n",
       "      <td>10.084097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  Appliances  lights     T1       RH_1    T2       RH_2  \\\n",
       "0  2016-01-11 17:00:00          60      30  19.89  47.596667  19.2  44.790000   \n",
       "1  2016-01-11 17:10:00          60      30  19.89  46.693333  19.2  44.722500   \n",
       "2  2016-01-11 17:20:00          50      30  19.89  46.300000  19.2  44.626667   \n",
       "3  2016-01-11 17:30:00          50      40  19.89  46.066667  19.2  44.590000   \n",
       "4  2016-01-11 17:40:00          60      40  19.89  46.333333  19.2  44.530000   \n",
       "\n",
       "      T3       RH_3         T4  ...         T9   RH_9     T_out  Press_mm_hg  \\\n",
       "0  19.79  44.730000  19.000000  ...  17.033333  45.53  6.600000        733.5   \n",
       "1  19.79  44.790000  19.000000  ...  17.066667  45.56  6.483333        733.6   \n",
       "2  19.79  44.933333  18.926667  ...  17.000000  45.50  6.366667        733.7   \n",
       "3  19.79  45.000000  18.890000  ...  17.000000  45.40  6.250000        733.8   \n",
       "4  19.79  45.000000  18.890000  ...  17.000000  45.40  6.133333        733.9   \n",
       "\n",
       "   RH_out  Windspeed  Visibility  Tdewpoint        rv1        rv2  \n",
       "0    92.0   7.000000   63.000000        5.3  13.275433  13.275433  \n",
       "1    92.0   6.666667   59.166667        5.2  18.606195  18.606195  \n",
       "2    92.0   6.333333   55.333333        5.1  28.642668  28.642668  \n",
       "3    92.0   6.000000   51.500000        5.0  45.410389  45.410389  \n",
       "4    92.0   5.666667   47.666667        4.9  10.084097  10.084097  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows in dataset is -  19735\n",
      "The number of columns in dataset is -  29\n"
     ]
    }
   ],
   "source": [
    "print('The number of rows in dataset is - ' , data.shape[0])\n",
    "print('The number of columns in dataset is - ' , data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           0\n",
       "Tdewpoint      0\n",
       "Visibility     0\n",
       "Windspeed      0\n",
       "RH_out         0\n",
       "Press_mm_hg    0\n",
       "T_out          0\n",
       "RH_9           0\n",
       "T9             0\n",
       "RH_8           0\n",
       "T8             0\n",
       "RH_7           0\n",
       "T7             0\n",
       "rv1            0\n",
       "RH_6           0\n",
       "RH_5           0\n",
       "T5             0\n",
       "RH_4           0\n",
       "T4             0\n",
       "RH_3           0\n",
       "T3             0\n",
       "RH_2           0\n",
       "T2             0\n",
       "RH_1           0\n",
       "T1             0\n",
       "lights         0\n",
       "Appliances     0\n",
       "T6             0\n",
       "rv2            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of null values in all columns\n",
    "data.isnull().sum().sort_values(ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 75% of the data is usedfor the training of the models and the rest is used for testing\n",
    "train, test = train_test_split(data,test_size=0.25,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the columns based on type for clear column management \n",
    "\n",
    "col_time=[\"date\"]\n",
    "\n",
    "col_temp = [\"T1\",\"T2\",\"T3\",\"T4\",\"T5\",\"T6\",\"T7\",\"T8\",\"T9\"]\n",
    "\n",
    "col_hum = [\"RH_1\",\"RH_2\",\"RH_3\",\"RH_4\",\"RH_5\",\"RH_6\",\"RH_7\",\"RH_8\",\"RH_9\"]\n",
    "\n",
    "col_weather = [\"T_out\", \"Tdewpoint\",\"RH_out\",\"Press_mm_hg\",\n",
    "                \"Windspeed\",\"Visibility\"] \n",
    "col_light = [\"lights\"]\n",
    "\n",
    "col_randoms = [\"rv1\", \"rv2\"]\n",
    "\n",
    "col_target = [\"Appliances\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate dependent and independent variables \n",
    "feature_vars = train[ col_time + col_temp + col_hum + col_weather + col_light + col_randoms ]\n",
    "target_vars = train[col_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     11438\n",
       "10     1649\n",
       "20     1230\n",
       "30      414\n",
       "40       64\n",
       "50        5\n",
       "60        1\n",
       "Name: lights, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution of values in lights column\n",
    "feature_vars.lights.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adityasingh/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# Due to lot of zero enteries this column is of not much use and will be ignored in rest of the model\n",
    "_ = feature_vars.drop(['lights'], axis=1 , inplace= True) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>...</th>\n",
       "      <th>RH_8</th>\n",
       "      <th>RH_9</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9544</th>\n",
       "      <td>2016-03-17 23:40:00</td>\n",
       "      <td>22.6</td>\n",
       "      <td>19.5</td>\n",
       "      <td>21.50</td>\n",
       "      <td>22.89</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>2.863333</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.89</td>\n",
       "      <td>19.89</td>\n",
       "      <td>...</td>\n",
       "      <td>38.5</td>\n",
       "      <td>37.26</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>87.666667</td>\n",
       "      <td>764.200000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>43.195492</td>\n",
       "      <td>43.195492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19366</th>\n",
       "      <td>2016-05-25 04:40:00</td>\n",
       "      <td>23.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.39</td>\n",
       "      <td>23.60</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.20</td>\n",
       "      <td>22.60</td>\n",
       "      <td>...</td>\n",
       "      <td>43.4</td>\n",
       "      <td>44.59</td>\n",
       "      <td>6.266667</td>\n",
       "      <td>5.3</td>\n",
       "      <td>93.666667</td>\n",
       "      <td>757.233333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.333333</td>\n",
       "      <td>46.369677</td>\n",
       "      <td>46.369677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date    T1    T2     T3     T4         T5        T6  \\\n",
       "9544   2016-03-17 23:40:00  22.6  19.5  21.50  22.89  19.166667  2.863333   \n",
       "19366  2016-05-25 04:40:00  23.7  21.0  25.39  23.60  19.890000  5.500000   \n",
       "\n",
       "         T7     T8     T9  ...  RH_8   RH_9     T_out  Tdewpoint     RH_out  \\\n",
       "9544   21.0  22.89  19.89  ...  38.5  37.26  2.233333        0.4  87.666667   \n",
       "19366  23.0  24.20  22.60  ...  43.4  44.59  6.266667        5.3  93.666667   \n",
       "\n",
       "       Press_mm_hg  Windspeed  Visibility        rv1        rv2  \n",
       "9544    764.200000   1.333333   61.000000  43.195492  43.195492  \n",
       "19366   757.233333   1.000000   25.333333  46.369677  46.369677  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vars.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly\n",
    "import plotly.plotly as py\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# To understand the timeseries variation of the applaince energy consumption\n",
    "visData = go.Scatter( x= data.date  ,  mode = \"lines\", y = data.Appliances )\n",
    "layout = go.Layout(title = 'Appliance energy consumption pattern' , xaxis=dict(title='Date'), yaxis=dict(title='(Wh)'))\n",
    "fig = go.Figure(data=[visData],layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding column to mark weekdays (0) and weekends(1) for time series evaluation , \n",
    "# decided not to use it for model evaluation as it has least impact\n",
    "\n",
    "data['WEEKDAY'] = ((pd.to_datetime(data['date']).dt.dayofweek)// 5 == 1).astype(float)\n",
    "# There are 5472 weekend recordings \n",
    "data['WEEKDAY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows with weekday \n",
    "temp_weekday =  data[data['WEEKDAY'] == 0]\n",
    "# To understand the timeseries variation of the applaince energy consumption\n",
    "visData = go.Scatter( x= temp_weekday.date  ,  mode = \"lines\", y = temp_weekday.Appliances )\n",
    "layout = go.Layout(title = 'Appliance energy consumption pattern on weekdays' , xaxis=dict(title='Date'), yaxis=dict(title='(Wh)'))\n",
    "fig = go.Figure(data=[visData],layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows with weekend \n",
    "\n",
    "temp_weekend =  data[data['WEEKDAY'] == 1]\n",
    "\n",
    "# To understand the timeseries variation of the applaince energy consumption\n",
    "visData = go.Scatter( x= temp_weekend.date  ,  mode = \"lines\", y = temp_weekend.Appliances )\n",
    "layout = go.Layout(title = 'Appliance energy consumption pattern on weekend' , xaxis=dict(title='Date'), yaxis=dict(title='(Wh)'))\n",
    "fig = go.Figure(data=[visData],layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of all the features to understand the distribution\n",
    "feature_vars.hist(bins = 20 , figsize= (12,16)) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focussed displots for RH_6 , RH_out , Visibility , Windspeed due to irregular distribution\n",
    "f, ax = plt.subplots(2,2,figsize=(12,8))\n",
    "vis1 = sns.distplot(feature_vars[\"RH_6\"],bins=10, ax= ax[0][0])\n",
    "vis2 = sns.distplot(feature_vars[\"RH_out\"],bins=10, ax=ax[0][1])\n",
    "vis3 = sns.distplot(feature_vars[\"Visibility\"],bins=10, ax=ax[1][0])\n",
    "vis4 = sns.distplot(feature_vars[\"Windspeed\"],bins=10, ax=ax[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of values in Applainces column\n",
    "f = plt.figure(figsize=(12,5))\n",
    "plt.xlabel('Appliance consumption in Wh')\n",
    "plt.ylabel('Frequency')\n",
    "sns.distplot(target_vars , bins=10 ) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appliance column range with consumption less than 200 Wh\n",
    "print('Percentage of the appliance consumption is less than 200 Wh')\n",
    "print(((target_vars[target_vars <= 200].count()) / (len(target_vars)))*100 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the weather , temperature , applainces and random column to see the correlation\n",
    "train_corr = train[col_temp + col_hum + col_weather +col_target+col_randoms]\n",
    "corr = train_corr.corr()\n",
    "# Mask the repeated values\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "  \n",
    "f, ax = plt.subplots(figsize=(16, 14))\n",
    "#Generate Heat Map, allow annotations and place floats in map\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\" , mask=mask,)\n",
    "    #Apply xticks\n",
    "plt.xticks(range(len(corr.columns)), corr.columns);\n",
    "    #Apply yticks\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    #show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "# Function to get top correlations \n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "print(\"Top Absolute Correlations\")\n",
    "print(get_top_abs_correlations(train_corr, 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training dataset into independent and dependent varibales\n",
    "train_X = train[feature_vars.columns]\n",
    "train_y = train[target_vars.columns]\n",
    "train_X.drop(['date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boruta algorith for feature selection\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from boruta import BorutaPy\n",
    "from datetime import datetime\n",
    "\n",
    "X=train_X.values\n",
    "y=train_y.values\n",
    "y=y.ravel()\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n",
    "\n",
    "rfc = RandomForestRegressor(n_estimators=100, max_depth=6, criterion='mse')\n",
    "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2)\n",
    "start_time = timer(None)\n",
    "boruta_selector.fit(X, y)\n",
    "timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta_selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta_selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split testing dataset into independent and dependent varibales\n",
    "test_X = test[feature_vars.columns]\n",
    "test_y = test[target_vars.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to conlusion made above below columns are removed\n",
    "train_X.drop([\"rv1\",\"rv2\",\"Visibility\",\"T6\",\"T9\"],axis=1 , inplace=True)\n",
    "\n",
    "# Due to conlusion made above below columns are removed\n",
    "test_X.drop([\"rv1\",\"rv2\",\"Visibility\",\"T6\",\"T9\",\"date\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "\n",
    "# Create test and training set by including Appliances column\n",
    "\n",
    "train = train[list(train_X.columns.values) + col_target ]\n",
    "\n",
    "test = test[list(test_X.columns.values) + col_target ]\n",
    "\n",
    "# Create dummy test and training set to hold scaled values\n",
    "\n",
    "sc_train = pd.DataFrame(columns=train.columns , index=train.index)\n",
    "\n",
    "sc_train[sc_train.columns] = sc.fit_transform(train)\n",
    "\n",
    "sc_test= pd.DataFrame(columns=test.columns , index=test.index)\n",
    "\n",
    "sc_test[sc_test.columns] = sc.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Appliances column from traininig set\n",
    "\n",
    "train_X =  sc_train.drop(['Appliances'] , axis=1)\n",
    "train_y = sc_train['Appliances']\n",
    "\n",
    "test_X =  sc_test.drop(['Appliances'] , axis=1)\n",
    "test_y = sc_test['Appliances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "\n",
    "models = [\n",
    "           ['RandomForest ',RandomForestRegressor()],\n",
    "           ['ExtraTreeRegressor :',ExtraTreesRegressor()]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all the proposed models and update the information in a list model_data\n",
    "import time\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model_data = []\n",
    "for name,curr_model in models :\n",
    "    curr_model_data = {}\n",
    "    curr_model.random_state = 78\n",
    "    curr_model_data[\"Name\"] = name\n",
    "    start = time.time()\n",
    "    curr_model.fit(train_X,train_y)\n",
    "    end = time.time()\n",
    "    curr_model_data[\"Train_Time\"] = end - start\n",
    "    curr_model_data[\"Train_R2_Score\"] = metrics.r2_score(train_y,curr_model.predict(train_X))\n",
    "    curr_model_data[\"Test_R2_Score\"] = metrics.r2_score(test_y,curr_model.predict(test_X))\n",
    "    curr_model_data[\"Test_RMSE_Score\"] = sqrt(mean_squared_error(test_y,curr_model.predict(test_X)))\n",
    "    model_data.append(curr_model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(model_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x=\"Name\", y=['Test_R2_Score' , 'Train_R2_Score' , 'Test_RMSE_Score'], kind=\"bar\" , title = 'R2 Score Results' , figsize= (10,8)) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [{\n",
    "              'max_depth': [80, 150, 200,250],\n",
    "              'n_estimators' : [100,150,200,250],\n",
    "              'max_features': [\"auto\", \"sqrt\", \"log2\"]\n",
    "            }]\n",
    "reg = ExtraTreesRegressor(random_state=40)\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = reg, param_grid = param_grid, cv = 5, n_jobs = -1 , scoring='r2' , verbose=2)\n",
    "grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned parameter set\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best possible parameters for ExtraTreesRegressor\n",
    "grid_search.best_estimator_\n",
    "\n",
    "# R2 score on training set with tuned parameters\n",
    "\n",
    "grid_search.best_estimator_.score(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 score on test set with tuned parameters\n",
    "grid_search.best_estimator_.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE score on test set with tuned parameters\n",
    "\n",
    "np.sqrt(mean_squared_error(test_y, grid_search.best_estimator_.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sorted list of features in order of importance\n",
    "feature_indices = np.argsort(grid_search.best_estimator_.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = grid_search.best_estimator_.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "names = [train_X.columns[i] for i in indices]\n",
    "# Create plot\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Create plot title\n",
    "plt.title(\"Feature Importance\")\n",
    "\n",
    "# Add bars\n",
    "plt.bar(range(train_X.shape[1]), importances[indices])\n",
    "\n",
    "# Add feature names as x-axis labels\n",
    "plt.xticks(range(train_X.shape[1]), names, rotation=90)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import concatenate\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import to_datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(dataset, n_in=1, n_out=1, dropnan=True):\n",
    "    num_vars = 1 if type(dataset) is list else dataset.shape[1]\n",
    "    dataframe = DataFrame(dataset)\n",
    "    cols, names = list(), list()\n",
    "    \n",
    "    # input sequence (t-n, ....t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(dataframe.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(num_vars)]\n",
    "    # forecast sequence (t, t+1 .... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(dataframe.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(num_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(num_vars)]\n",
    "    \n",
    "    # put it all together \n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    \n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=[\"RH_out\",\"RH_8\",\"RH_1\",\"T3\",\"RH_3\",\"T2\",\"Press_mm_hg\",\"RH_2\",\"RH_7\",\"T8\",\"RH_6\",\"RH_4\",\"RH_5\",\"T_out\",\"RH_9\",\n",
    "             \"T4\",\"T7\",\"Tdewpoint\",\"Windspeed\",\"T1\",\"T5\"]\n",
    "data1 = data[col_target + col_time + feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data1[\"date\"]=pd.to_datetime(data1[\"date\"])\n",
    "data1 = data1.set_index(['date'], drop=True)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values=data1.values\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed = series_to_supervised(scaled, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed.drop(reframed.columns[[22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = reframed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = values[:,:21]\n",
    "Y = values[:,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "X_Train = X_Train.reshape((X_Train.shape[0], 1, X_Train.shape[1]))\n",
    "X_Test = X_Test.reshape((X_Test.shape[0], 1, X_Test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_Train.shape[1], X_Train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fit\n",
    "history = model.fit(X_Train, Y_Train, epochs=70, batch_size=10, validation_data=(X_Test, Y_Test), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.plot(history.history['loss'], label='Train')\n",
    "pyplot.plot(history.history['val_loss'], label='Test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sca=DataFrame(scaled)\n",
    "sca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_test_mse = model.evaluate(X_Test, Y_Test, batch_size=1)\n",
    "print('Test MSE: %f'%lstm_test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred_test_lstm = model.predict(X_Test)\n",
    "y_train_pred_lstm = model.predict(X_Train)\n",
    "print(\"The R2 score on the Train set is:\\t{:0.3f}\".format(r2_score(Y_Train, y_train_pred_lstm)))\n",
    "print(\"The R2 score on the Test set is:\\t{:0.3f}\".format(r2_score(Y_Test, y_pred_test_lstm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_y_pred_test = model.predict(X_Test)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(Y_Test, label='True')\n",
    "plt.plot(y_pred_test_lstm, label='LSTM')\n",
    "plt.title(\"LSTM's Prediction\")\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('Appliances scaled')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(X_Test)\n",
    "X_Test = X_Test.reshape((X_Test.shape[0], 21))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, X_Test[:, -21:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "Y_Test = Y_Test.reshape((len(Y_Test), 1))\n",
    "inv_y = np.concatenate((Y_Test, X_Test[:, -21:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
